use crate::languages::{Language, LanguageAnalysisResult, LanguageAnalyzerFactory};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// ä»£ç å®¡æŸ¥æœåŠ¡ï¼Œç”¨äºè‡ªåŠ¨è¯†åˆ«è¯­è¨€å¹¶è¿›è¡Œåˆ†æ
pub struct CodeReviewService;

/// æ–‡ä»¶åˆ†æç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileAnalysisResult {
    pub file_path: String,
    pub language: Language,
    pub analysis: LanguageAnalysisResult,
}

/// ä»£ç å®¡æŸ¥æŠ¥å‘Š
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CodeReviewReport {
    pub files: Vec<FileAnalysisResult>,
    pub summary: ReviewSummary,
}

/// å®¡æŸ¥æ‘˜è¦
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReviewSummary {
    pub total_files: usize,
    pub languages_detected: HashMap<Language, usize>,
    pub total_features: usize,
    pub common_patterns: Vec<String>,
    pub overall_risks: Vec<String>,
    pub test_suggestions: Vec<String>,
}

impl CodeReviewService {
    pub fn new() -> Self {
        CodeReviewService
    }

    /// è‡ªåŠ¨è¯†åˆ«æ–‡ä»¶è¯­è¨€
    pub fn detect_language(&self, file_path: &str) -> Language {
        Language::from_file_path(file_path)
    }

    /// åˆ†æå•ä¸ªæ–‡ä»¶
    pub fn analyze_file(&self, file_path: &str, file_content: &str) -> FileAnalysisResult {
        let language = self.detect_language(file_path);
        let analyzer = LanguageAnalyzerFactory::create_analyzer(&language);

        // å°†æ–‡ä»¶å†…å®¹æŒ‰è¡Œåˆ†å‰²å¹¶åˆ†æ
        let lines: Vec<&str> = file_content.lines().collect();

        // åªåˆ†ææ–°å¢çš„è¡Œï¼ˆåœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¿™äº›åº”è¯¥ä»git diffä¸­æå–ï¼‰
        let added_lines: Vec<String> = lines.iter().map(|&line| line.to_string()).collect();

        let analysis = analyzer.analyze_file_changes(file_path, &added_lines);

        FileAnalysisResult {
            file_path: file_path.to_string(),
            language,
            analysis,
        }
    }

    /// ä»Git diffåˆ†æå˜æ›´çš„æ–‡ä»¶
    pub fn analyze_git_diff(&self, diff_content: &str) -> Vec<FileAnalysisResult> {
        let mut results = Vec::new();
        let parsed_diff = self.parse_git_diff(diff_content);

        for (file_path, added_lines) in parsed_diff {
            let language = self.detect_language(&file_path);
            let analyzer = LanguageAnalyzerFactory::create_analyzer(&language);
            let analysis = analyzer.analyze_file_changes(&file_path, &added_lines);

            results.push(FileAnalysisResult {
                file_path,
                language,
                analysis,
            });
        }

        results
    }

    /// è§£æGit diffå†…å®¹
    fn parse_git_diff(&self, diff_content: &str) -> Vec<(String, Vec<String>)> {
        let mut files = Vec::new();
        let mut current_file = String::new();
        let mut added_lines = Vec::new();

        for line in diff_content.lines() {
            if line.starts_with("diff --git") {
                // ä¿å­˜å‰ä¸€ä¸ªæ–‡ä»¶çš„ç»“æœ
                if !current_file.is_empty() && !added_lines.is_empty() {
                    files.push((current_file.clone(), added_lines.clone()));
                }

                // å¼€å§‹æ–°æ–‡ä»¶
                current_file = String::new();
                added_lines.clear();
            } else if line.starts_with("+++") {
                // æå–æ–‡ä»¶è·¯å¾„
                let parts: Vec<&str> = line.split_whitespace().collect();
                if parts.len() >= 2 {
                    current_file = parts[1].trim_start_matches("b/").to_string();
                }
            } else if line.starts_with('+') && !line.starts_with("+++") {
                // è¿™æ˜¯æ–°å¢çš„è¡Œ
                added_lines.push(line[1..].to_string()); // ç§»é™¤'+'å‰ç¼€
            }
        }

        // æ·»åŠ æœ€åä¸€ä¸ªæ–‡ä»¶
        if !current_file.is_empty() && !added_lines.is_empty() {
            files.push((current_file, added_lines));
        }

        files
    }

    /// åˆ†æå¤šä¸ªæ–‡ä»¶å¹¶ç”ŸæˆæŠ¥å‘Š
    pub fn analyze_files(&self, file_paths: &[String]) -> CodeReviewReport {
        let mut file_results = Vec::new();

        for file_path in file_paths {
            // å°è¯•è¯»å–å®é™…æ–‡ä»¶å†…å®¹
            let file_content = match std::fs::read_to_string(file_path) {
                Ok(content) => content,
                Err(_) => {
                    // å¦‚æœè¯»å–å¤±è´¥ï¼Œè·³è¿‡è¯¥æ–‡ä»¶
                    eprintln!("è­¦å‘Š: æ— æ³•è¯»å–æ–‡ä»¶ {}", file_path);
                    continue;
                }
            };

            let result = self.analyze_file(file_path, &file_content);
            file_results.push(result);
        }

        let summary = self.generate_summary(&file_results);

        CodeReviewReport {
            files: file_results,
            summary,
        }
    }

    /// ä»Git diffç”Ÿæˆå®Œæ•´çš„ä»£ç å®¡æŸ¥æŠ¥å‘Š
    pub fn review_git_changes(&self, diff_content: &str) -> CodeReviewReport {
        let file_results = self.analyze_git_diff(diff_content);
        let summary = self.generate_summary(&file_results);

        CodeReviewReport {
            files: file_results,
            summary,
        }
    }

    /// ç”Ÿæˆå®¡æŸ¥æ‘˜è¦
    fn generate_summary(&self, file_results: &[FileAnalysisResult]) -> ReviewSummary {
        let mut languages_detected = HashMap::new();
        let mut total_features = 0;
        let mut all_patterns = Vec::new();
        let mut all_risks = Vec::new();
        let mut all_test_suggestions = Vec::new();

        for result in file_results {
            // ç»Ÿè®¡è¯­è¨€
            *languages_detected
                .entry(result.language.clone())
                .or_insert(0) += 1;

            // ç»Ÿè®¡ç‰¹å¾
            total_features += result.analysis.features.len();

            // æ”¶é›†æ¨¡å¼
            all_patterns.extend(result.analysis.change_patterns.clone());

            // æ”¶é›†é£é™©å’Œæµ‹è¯•å»ºè®®
            let analyzer = LanguageAnalyzerFactory::create_analyzer(&result.language);
            all_risks.extend(analyzer.assess_risks(&result.analysis.features));
            all_test_suggestions
                .extend(analyzer.generate_test_suggestions(&result.analysis.features));
        }

        // å»é‡å¹¶æ’åº
        all_patterns.sort();
        all_patterns.dedup();
        all_risks.sort();
        all_risks.dedup();
        all_test_suggestions.sort();
        all_test_suggestions.dedup();

        ReviewSummary {
            total_files: file_results.len(),
            languages_detected,
            total_features,
            common_patterns: all_patterns,
            overall_risks: all_risks,
            test_suggestions: all_test_suggestions,
        }
    }

    /// æ ¼å¼åŒ–æŠ¥å‘Šä¸ºå¯è¯»æ–‡æœ¬ï¼Œæ”¯æŒå†…å®¹é•¿åº¦ä¼˜åŒ–
    pub fn format_report(&self, report: &CodeReviewReport) -> String {
        let initial_report = self.format_report_internal(report, false);

        // æ£€æŸ¥æŠ¥å‘Šé•¿åº¦æ˜¯å¦è¿‡é•¿ï¼ˆè¶…è¿‡ 10000 å­—ç¬¦ï¼‰
        if initial_report.len() > 10000 {
            // ç”Ÿæˆä¼˜åŒ–ç‰ˆæœ¬çš„æŠ¥å‘Š
            self.format_report_internal(report, true)
        } else {
            initial_report
        }
    }

    /// å†…éƒ¨æ ¼å¼åŒ–æ–¹æ³•ï¼Œæ”¯æŒä¼˜åŒ–æ¨¡å¼
    fn format_report_internal(&self, report: &CodeReviewReport, optimize: bool) -> String {
        let mut output = String::new();

        output.push_str("# ä»£ç å®¡æŸ¥æŠ¥å‘Š\n\n");

        // æ‘˜è¦éƒ¨åˆ†
        output.push_str("## ğŸ“Š æ‘˜è¦ç»Ÿè®¡\n\n");
        output.push_str(&format!("- **æ€»æ–‡ä»¶æ•°**: {}\n", report.summary.total_files));
        output.push_str(&format!(
            "- **æ£€æµ‹åˆ°çš„ç‰¹å¾æ•°**: {}\n",
            report.summary.total_features
        ));
        output.push_str("- **æ£€æµ‹åˆ°çš„è¯­è¨€**:\n");

        for (language, count) in &report.summary.languages_detected {
            output.push_str(&format!("  - {}: {} ä¸ªæ–‡ä»¶\n", language.as_str(), count));
        }
        output.push('\n');

        // å˜æ›´æ¨¡å¼ - ä¼˜åŒ–æ¨¡å¼ä¸‹é™åˆ¶æ•°é‡
        if !report.summary.common_patterns.is_empty() {
            output.push_str("## ğŸ” å˜æ›´æ¨¡å¼åˆ†æ\n\n");
            let patterns = if optimize {
                // ä¼˜åŒ–æ¨¡å¼ï¼šåªæ˜¾ç¤ºå‰5ä¸ªæœ€é‡è¦çš„æ¨¡å¼
                report
                    .summary
                    .common_patterns
                    .iter()
                    .take(5)
                    .collect::<Vec<_>>()
            } else {
                report.summary.common_patterns.iter().collect::<Vec<_>>()
            };

            for pattern in patterns {
                output.push_str(&format!("- {}\n", pattern));
            }

            if optimize && report.summary.common_patterns.len() > 5 {
                output.push_str(&format!(
                    "- ... åŠå…¶ä»– {} ä¸ªå˜æ›´æ¨¡å¼\n",
                    report.summary.common_patterns.len() - 5
                ));
            }
            output.push('\n');
        }

        // é£é™©è¯„ä¼° - ä¼˜åŒ–æ¨¡å¼ä¸‹é™åˆ¶æ•°é‡
        if !report.summary.overall_risks.is_empty() {
            output.push_str("## âš ï¸  é£é™©è¯„ä¼°\n\n");
            let risks = if optimize {
                // ä¼˜åŒ–æ¨¡å¼ï¼šåªæ˜¾ç¤ºå‰5ä¸ªæœ€é‡è¦çš„é£é™©
                report
                    .summary
                    .overall_risks
                    .iter()
                    .take(5)
                    .collect::<Vec<_>>()
            } else {
                report.summary.overall_risks.iter().collect::<Vec<_>>()
            };

            for risk in risks {
                output.push_str(&format!("- {}\n", risk));
            }

            if optimize && report.summary.overall_risks.len() > 5 {
                output.push_str(&format!(
                    "- ... åŠå…¶ä»– {} ä¸ªé£é™©é¡¹\n",
                    report.summary.overall_risks.len() - 5
                ));
            }
            output.push('\n');
        }

        // æµ‹è¯•å»ºè®® - ä¼˜åŒ–æ¨¡å¼ä¸‹é™åˆ¶æ•°é‡
        if !report.summary.test_suggestions.is_empty() {
            output.push_str("## ğŸ§ª æµ‹è¯•å»ºè®®\n\n");
            let suggestions = if optimize {
                // ä¼˜åŒ–æ¨¡å¼ï¼šåªæ˜¾ç¤ºå‰8ä¸ªæœ€é‡è¦çš„å»ºè®®
                report
                    .summary
                    .test_suggestions
                    .iter()
                    .take(8)
                    .collect::<Vec<_>>()
            } else {
                report.summary.test_suggestions.iter().collect::<Vec<_>>()
            };

            for suggestion in suggestions {
                output.push_str(&format!("- {}\n", suggestion));
            }

            if optimize && report.summary.test_suggestions.len() > 8 {
                output.push_str(&format!(
                    "- ... åŠå…¶ä»– {} ä¸ªæµ‹è¯•å»ºè®®\n",
                    report.summary.test_suggestions.len() - 8
                ));
            }
            output.push('\n');
        }

        // è¯¦ç»†æ–‡ä»¶åˆ†æ - ä¼˜åŒ–æ¨¡å¼ä¸‹é™åˆ¶è¯¦ç»†ç¨‹åº¦
        output.push_str("## ğŸ“ è¯¦ç»†æ–‡ä»¶åˆ†æ\n\n");

        let files_to_show = if optimize {
            // ä¼˜åŒ–æ¨¡å¼ï¼šåªæ˜¾ç¤ºå‰10ä¸ªæ–‡ä»¶
            report.files.iter().take(10).collect::<Vec<_>>()
        } else {
            report.files.iter().collect::<Vec<_>>()
        };

        for file_result in files_to_show {
            output.push_str(&format!(
                "### {} ({})\n\n",
                file_result.file_path,
                file_result.language.as_str()
            ));

            if !file_result.analysis.features.is_empty() {
                output.push_str("**æ£€æµ‹åˆ°çš„ç‰¹å¾**:\n");

                let features_to_show = if optimize {
                    // ä¼˜åŒ–æ¨¡å¼ï¼šæ¯ä¸ªæ–‡ä»¶æœ€å¤šæ˜¾ç¤º5ä¸ªç‰¹å¾
                    file_result
                        .analysis
                        .features
                        .iter()
                        .take(5)
                        .collect::<Vec<_>>()
                } else {
                    file_result.analysis.features.iter().collect::<Vec<_>>()
                };

                for feature in features_to_show {
                    output.push_str(&format!(
                        "- **{}**: {} (è¡Œ {})\n",
                        feature.feature_type,
                        feature.name,
                        feature.line_number.unwrap_or(0)
                    ));
                }

                if optimize && file_result.analysis.features.len() > 5 {
                    output.push_str(&format!(
                        "- ... åŠå…¶ä»– {} ä¸ªç‰¹å¾\n",
                        file_result.analysis.features.len() - 5
                    ));
                }
                output.push('\n');
            }

            if !file_result.analysis.scope_suggestions.is_empty() {
                output.push_str("**ä½œç”¨åŸŸå»ºè®®**: ");
                if optimize {
                    // ä¼˜åŒ–æ¨¡å¼ï¼šæœ€å¤šæ˜¾ç¤ºå‰3ä¸ªä½œç”¨åŸŸå»ºè®®
                    let suggestions_to_show: Vec<&String> = file_result
                        .analysis
                        .scope_suggestions
                        .iter()
                        .take(3)
                        .collect();
                    output.push_str(
                        &suggestions_to_show
                            .iter()
                            .map(|s| s.as_str())
                            .collect::<Vec<&str>>()
                            .join(", "),
                    );

                    if file_result.analysis.scope_suggestions.len() > 3 {
                        output.push_str(&format!(
                            ", ... (+{})",
                            file_result.analysis.scope_suggestions.len() - 3
                        ));
                    }
                } else {
                    output.push_str(&file_result.analysis.scope_suggestions.join(", "));
                }
                output.push_str("\n\n");
            }
        }

        // å¦‚æœä¼˜åŒ–æ¨¡å¼ä¸‹æœ‰çœç•¥çš„æ–‡ä»¶ï¼Œæ·»åŠ è¯´æ˜
        if optimize && report.files.len() > 10 {
            output.push_str(&format!(
                "### ... åŠå…¶ä»– {} ä¸ªæ–‡ä»¶\n\n",
                report.files.len() - 10
            ));
            output.push_str("*ä¸ºä¿æŒæŠ¥å‘Šç®€æ´ï¼Œè¯¦ç»†åˆ†æå·²é™åˆ¶åœ¨å‰10ä¸ªæ–‡ä»¶ã€‚å¦‚éœ€æŸ¥çœ‹å®Œæ•´æŠ¥å‘Šï¼Œè¯·ä½¿ç”¨ `--review-format json` è·å–å®Œæ•´æ•°æ®ã€‚*\n\n");
        }

        output
    }
}

impl Default for CodeReviewService {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_language_detection() {
        let service = CodeReviewService::new();

        assert_eq!(service.detect_language("main.go"), Language::Go);
        assert_eq!(
            service.detect_language("component.tsx"),
            Language::TypeScript
        );
        assert_eq!(service.detect_language("script.js"), Language::JavaScript);
        assert_eq!(service.detect_language("lib.rs"), Language::Rust);
        assert_eq!(service.detect_language("config.json"), Language::Unknown);
    }

    #[test]
    fn test_file_analysis() {
        let service = CodeReviewService::new();
        let go_content = r#"
package main

import "fmt"

func main() {
    fmt.Println("Hello, World!")
}
"#;

        let result = service.analyze_file("main.go", go_content);
        assert_eq!(result.language, Language::Go);
        assert_eq!(result.file_path, "main.go");
        assert!(!result.analysis.features.is_empty());
    }

    #[test]
    fn test_git_diff_parsing() {
        let service = CodeReviewService::new();
        let diff_content = r#"
diff --git a/src/main.go b/src/main.go
index 1234567..abcdefg 100644
--- a/src/main.go
+++ b/src/main.go
@@ -1,3 +1,5 @@
 package main
 
+import "fmt"
+
 func main() {
"#;

        let results = service.analyze_git_diff(diff_content);
        assert_eq!(results.len(), 1);
        assert_eq!(results[0].file_path, "src/main.go");
        assert_eq!(results[0].language, Language::Go);
    }

    #[test]
    fn test_report_generation() {
        let service = CodeReviewService::new();
        let files = vec![
            "src/main.go".to_string(),
            "components/Button.tsx".to_string(),
            "utils/helper.js".to_string(),
        ];

        let report = service.analyze_files(&files);
        assert_eq!(report.files.len(), 0); // æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ‰€ä»¥ç»“æœä¸º0
        assert!(report.summary.languages_detected.is_empty());

        let formatted = service.format_report(&report);
        assert!(formatted.contains("ä»£ç å®¡æŸ¥æŠ¥å‘Š"));
        assert!(formatted.contains("æ‘˜è¦ç»Ÿè®¡"));
    }

    #[test]
    fn test_content_length_optimization() {
        let service = CodeReviewService::new();

        // åˆ›å»ºä¸€ä¸ªåŒ…å«å¤§é‡å†…å®¹çš„æ¨¡æ‹ŸæŠ¥å‘Š
        let mut large_report = CodeReviewReport {
            files: Vec::new(),
            summary: ReviewSummary {
                total_files: 50,
                languages_detected: {
                    let mut map = HashMap::new();
                    map.insert(Language::Rust, 30);
                    map.insert(Language::Go, 20);
                    map
                },
                total_features: 500,
                common_patterns: (0..20)
                    .map(|i| {
                        format!(
                            "å˜æ›´æ¨¡å¼ {} - è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æè¿°ï¼ŒåŒ…å«äº†è¯¦ç»†çš„æŠ€æœ¯ç»†èŠ‚å’Œå®ç°å»ºè®®",
                            i
                        )
                    })
                    .collect(),
                overall_risks: (0..15)
                    .map(|i| {
                        format!(
                            "é£é™©é¡¹ {} - è¿™æ˜¯ä¸€ä¸ªè¯¦ç»†çš„é£é™©æè¿°ï¼ŒåŒ…å«äº†æ½œåœ¨çš„å½±å“å’Œå»ºè®®çš„ç¼“è§£æªæ–½",
                            i
                        )
                    })
                    .collect(),
                test_suggestions: (0..25)
                    .map(|i| {
                        format!(
                            "æµ‹è¯•å»ºè®® {} - è¿™æ˜¯ä¸€ä¸ªè¯¦ç»†çš„æµ‹è¯•ç­–ç•¥å»ºè®®ï¼ŒåŒ…å«äº†å…·ä½“çš„å®ç°æ–¹æ³•",
                            i
                        )
                    })
                    .collect(),
            },
        };

        // æ·»åŠ å¤§é‡æ–‡ä»¶åˆ†æç»“æœ
        for i in 0..20 {
            large_report.files.push(FileAnalysisResult {
                file_path: format!("src/file_{}.rs", i),
                language: Language::Rust,
                analysis: LanguageAnalysisResult {
                    language: Language::Rust,
                    features: (0..10)
                        .map(|j| crate::languages::LanguageFeature {
                            feature_type: "function".to_string(),
                            name: format!("function_{}_{}", i, j),
                            line_number: Some(j + 1),
                            description: format!("è¿™æ˜¯ä¸€ä¸ªè¯¦ç»†çš„å‡½æ•°æè¿° {} {}", i, j),
                        })
                        .collect(),
                    scope_suggestions: vec![
                        "rust".to_string(),
                        "module".to_string(),
                        format!("file_{}", i),
                        "function".to_string(),
                        "implementation".to_string(),
                    ],
                    change_patterns: vec![format!("æ¨¡å¼ {}", i)],
                },
            });
        }

        // æµ‹è¯•åˆå§‹æŠ¥å‘Šé•¿åº¦
        let initial_report = service.format_report_internal(&large_report, false);
        assert!(initial_report.len() > 10000, "åˆå§‹æŠ¥å‘Šåº”è¯¥è¶…è¿‡é•¿åº¦é˜ˆå€¼");

        // æµ‹è¯•ä¼˜åŒ–æŠ¥å‘Šé•¿åº¦
        let optimized_report = service.format_report_internal(&large_report, true);
        assert!(
            optimized_report.len() < initial_report.len(),
            "ä¼˜åŒ–åçš„æŠ¥å‘Šåº”è¯¥æ›´çŸ­"
        );

        // æµ‹è¯•è‡ªåŠ¨ä¼˜åŒ–åŠŸèƒ½
        let auto_optimized = service.format_report(&large_report);
        assert_eq!(
            auto_optimized, optimized_report,
            "è‡ªåŠ¨ä¼˜åŒ–åº”è¯¥äº§ç”Ÿç›¸åŒçš„ç»“æœ"
        );

        // éªŒè¯ä¼˜åŒ–æŠ¥å‘ŠåŒ…å«çœç•¥æç¤º
        assert!(
            optimized_report.contains("åŠå…¶ä»–"),
            "ä¼˜åŒ–æŠ¥å‘Šåº”è¯¥åŒ…å«çœç•¥æç¤º"
        );
        assert!(
            optimized_report.contains("ä¸ºä¿æŒæŠ¥å‘Šç®€æ´"),
            "ä¼˜åŒ–æŠ¥å‘Šåº”è¯¥åŒ…å«è¯´æ˜æ–‡å­—"
        );
    }

    #[test]
    fn test_small_content_no_optimization() {
        let service = CodeReviewService::new();

        // åˆ›å»ºä¸€ä¸ªå°çš„æŠ¥å‘Š
        let small_report = CodeReviewReport {
            files: vec![FileAnalysisResult {
                file_path: "src/main.rs".to_string(),
                language: Language::Rust,
                analysis: LanguageAnalysisResult {
                    language: Language::Rust,
                    features: vec![crate::languages::LanguageFeature {
                        feature_type: "function".to_string(),
                        name: "main".to_string(),
                        line_number: Some(1),
                        description: "ä¸»å‡½æ•°".to_string(),
                    }],
                    scope_suggestions: vec!["main".to_string()],
                    change_patterns: vec!["å‡½æ•°å˜æ›´".to_string()],
                },
            }],
            summary: ReviewSummary {
                total_files: 1,
                languages_detected: {
                    let mut map = HashMap::new();
                    map.insert(Language::Rust, 1);
                    map
                },
                total_features: 1,
                common_patterns: vec!["å‡½æ•°å˜æ›´".to_string()],
                overall_risks: vec!["æ— é£é™©".to_string()],
                test_suggestions: vec!["æ·»åŠ æµ‹è¯•".to_string()],
            },
        };

        let report = service.format_report(&small_report);
        let unoptimized_report = service.format_report_internal(&small_report, false);

        // å°æŠ¥å‘Šåº”è¯¥ä¸è§¦å‘ä¼˜åŒ–
        assert_eq!(report, unoptimized_report, "å°æŠ¥å‘Šä¸åº”è¯¥è¢«ä¼˜åŒ–");
        assert!(!report.contains("åŠå…¶ä»–"), "å°æŠ¥å‘Šä¸åº”è¯¥åŒ…å«çœç•¥æç¤º");
    }
}
