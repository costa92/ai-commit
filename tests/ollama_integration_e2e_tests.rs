/// E2E æµ‹è¯•ï¼šOllama é›†æˆæµ‹è¯•
/// æµ‹è¯•ä¸çœŸå® Ollama æœåŠ¡çš„å®Œæ•´é›†æˆ

use std::env;
use std::process::Command;
use std::time::Duration;

use reqwest::Client;
use serde_json::{json, Value};
use tokio::time::timeout;

use ai_commit::config::Config;
use ai_commit::config::providers::ProviderRegistry;

/// æµ‹è¯•è¾…åŠ©å‡½æ•°ï¼šæ¸…ç†ç¯å¢ƒå˜é‡
fn clear_env_vars() {
    let vars = [
        "AI_COMMIT_PROVIDER",
        "AI_COMMIT_MODEL", 
        "AI_COMMIT_DEBUG",
        "AI_COMMIT_OLLAMA_URL",
    ];
    
    for var in &vars {
        env::remove_var(var);
    }
}

/// æ£€æŸ¥ Ollama æœåŠ¡æ˜¯å¦è¿è¡Œ
async fn check_ollama_service() -> bool {
    let client = Client::new();
    
    match timeout(Duration::from_secs(5), client.get("http://localhost:11434/api/tags").send()).await {
        Ok(Ok(response)) => response.status().is_success(),
        _ => false,
    }
}

/// è·å–å¯ç”¨çš„ Ollama æ¨¡å‹
async fn get_ollama_models() -> Result<Vec<String>, Box<dyn std::error::Error>> {
    let client = Client::new();
    
    let response = client
        .get("http://localhost:11434/api/tags")
        .send()
        .await?;
    
    let json: Value = response.json().await?;
    let models = json["models"]
        .as_array()
        .unwrap_or(&vec![])
        .iter()
        .filter_map(|model| {
            model["name"].as_str().map(|s| {
                // æå–æ¨¡å‹åç§°ï¼ˆå»æ‰ :latest åç¼€ï¼‰
                s.split(':').next().unwrap_or(s).to_string()
            })
        })
        .collect();
    
    Ok(models)
}

/// æµ‹è¯•ä¸ Ollama çš„åŸºæœ¬è¿æ¥
async fn test_ollama_connection(model: &str) -> Result<String, Box<dyn std::error::Error>> {
    let client = Client::new();
    
    let request_body = json!({
        "model": model,
        "prompt": "fix: æµ‹è¯•è¿æ¥",
        "stream": false
    });
    
    let response = client
        .post("http://localhost:11434/api/generate")
        .json(&request_body)
        .send()
        .await?;
    
    if !response.status().is_success() {
        return Err(format!("Ollama API é”™è¯¯: {}", response.status()).into());
    }
    
    let json: Value = response.json().await?;
    let generated_text = json["response"]
        .as_str()
        .unwrap_or("")
        .to_string();
    
    Ok(generated_text)
}

#[tokio::test]
async fn test_e2e_ollama_service_availability() {
    println!("ğŸ§ª E2E æµ‹è¯•ï¼šOllama æœåŠ¡å¯ç”¨æ€§");
    
    let is_available = check_ollama_service().await;
    
    if !is_available {
        println!("âš ï¸  Ollama æœåŠ¡æœªè¿è¡Œï¼Œè·³è¿‡é›†æˆæµ‹è¯•");
        println!("   å¯åŠ¨ Ollama: ollama serve");
        return;
    }
    
    println!("âœ… Ollama æœåŠ¡è¿è¡Œæ­£å¸¸");
    
    // è·å–å¯ç”¨æ¨¡å‹
    match get_ollama_models().await {
        Ok(models) => {
            println!("âœ… å¯ç”¨æ¨¡å‹: {:?}", models);
            assert!(!models.is_empty(), "åº”è¯¥è‡³å°‘æœ‰ä¸€ä¸ªæ¨¡å‹å¯ç”¨");
        }
        Err(e) => {
            panic!("è·å– Ollama æ¨¡å‹åˆ—è¡¨å¤±è´¥: {}", e);
        }
    }
}

#[tokio::test]
async fn test_e2e_ollama_config_integration() {
    println!("ğŸ§ª E2E æµ‹è¯•ï¼šOllama é…ç½®é›†æˆ");
    
    if !check_ollama_service().await {
        println!("âš ï¸  Ollama æœåŠ¡æœªè¿è¡Œï¼Œè·³è¿‡é›†æˆæµ‹è¯•");
        return;
    }
    
    clear_env_vars();
    
    // è®¾ç½® Ollama é…ç½®
    env::set_var("AI_COMMIT_PROVIDER", "ollama");
    env::set_var("AI_COMMIT_MODEL", "mistral");
    env::set_var("AI_COMMIT_DEBUG", "true");
    
    // åˆ›å»ºå¹¶éªŒè¯é…ç½®
    let mut config = Config::new();
    config.load_from_env();
    
    assert_eq!(config.provider, "ollama");
    assert_eq!(config.model, "mistral");
    assert!(config.debug);
    
    // éªŒè¯ Ollama æä¾›å•†ä¿¡æ¯
    let provider_info = config.current_provider_info().unwrap();
    assert_eq!(provider_info.name, "ollama");
    assert!(!provider_info.requires_api_key, "Ollama ä¸éœ€è¦ API Key");
    
    // éªŒè¯é…ç½®æœ‰æ•ˆæ€§
    let validation_result = config.validate();
    assert!(validation_result.is_ok(), "Ollama é…ç½®åº”è¯¥éªŒè¯é€šè¿‡: {:?}", validation_result);
    
    // éªŒè¯ URL é…ç½®
    assert_eq!(config.ollama_url(), "http://localhost:11434/api/generate");
    assert_eq!(config.current_url(), "http://localhost:11434/api/generate");
    assert_eq!(config.current_api_key(), None);
    
    println!("âœ… Ollama é…ç½®é›†æˆéªŒè¯é€šè¿‡");
    
    clear_env_vars();
}

#[tokio::test]
async fn test_e2e_ollama_api_call() {
    println!("ğŸ§ª E2E æµ‹è¯•ï¼šOllama API è°ƒç”¨");
    
    if !check_ollama_service().await {
        println!("âš ï¸  Ollama æœåŠ¡æœªè¿è¡Œï¼Œè·³è¿‡é›†æˆæµ‹è¯•");
        return;
    }
    
    // è·å–å¯ç”¨æ¨¡å‹
    let available_models = match get_ollama_models().await {
        Ok(models) => models,
        Err(e) => {
            println!("âš ï¸  æ— æ³•è·å– Ollama æ¨¡å‹: {}, è·³è¿‡ API æµ‹è¯•", e);
            return;
        }
    };
    
    if available_models.is_empty() {
        println!("âš ï¸  æ²¡æœ‰å¯ç”¨çš„ Ollama æ¨¡å‹ï¼Œè·³è¿‡ API æµ‹è¯•");
        println!("   å®‰è£…æ¨¡å‹: ollama pull mistral");
        return;
    }
    
    // ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹è¿›è¡Œæµ‹è¯•
    let test_model = &available_models[0];
    println!("ä½¿ç”¨æ¨¡å‹è¿›è¡Œæµ‹è¯•: {}", test_model);
    
    // æµ‹è¯• API è°ƒç”¨
    match test_ollama_connection(test_model).await {
        Ok(response) => {
            println!("âœ… Ollama API è°ƒç”¨æˆåŠŸ");
            println!("å“åº”å†…å®¹: {}", response.chars().take(100).collect::<String>());
            assert!(!response.is_empty(), "å“åº”ä¸åº”è¯¥ä¸ºç©º");
        }
        Err(e) => {
            panic!("Ollama API è°ƒç”¨å¤±è´¥: {}", e);
        }
    }
}

#[tokio::test]
async fn test_e2e_ollama_custom_url() {
    println!("ğŸ§ª E2E æµ‹è¯•ï¼šOllama è‡ªå®šä¹‰ URL");
    
    if !check_ollama_service().await {
        println!("âš ï¸  Ollama æœåŠ¡æœªè¿è¡Œï¼Œè·³è¿‡é›†æˆæµ‹è¯•");
        return;
    }
    
    clear_env_vars();
    
    // è®¾ç½®è‡ªå®šä¹‰ URL
    let custom_url = "http://localhost:11434/api/generate";
    env::set_var("AI_COMMIT_PROVIDER", "ollama");
    env::set_var("AI_COMMIT_OLLAMA_URL", custom_url);
    
    // åˆ›å»ºé…ç½®
    let mut config = Config::new();
    config.load_from_env();
    
    // éªŒè¯è‡ªå®šä¹‰ URL ç”Ÿæ•ˆ
    assert_eq!(config.ollama_url(), custom_url);
    assert_eq!(config.current_url(), custom_url);
    
    println!("âœ… Ollama è‡ªå®šä¹‰ URL é…ç½®éªŒè¯é€šè¿‡");
    
    clear_env_vars();
}

#[tokio::test]
async fn test_e2e_ollama_model_validation() {
    println!("ğŸ§ª E2E æµ‹è¯•ï¼šOllama æ¨¡å‹éªŒè¯");
    
    clear_env_vars();
    
    let mut config = Config::new();
    config.provider = "ollama".to_string();
    
    // æµ‹è¯•æ”¯æŒçš„æ¨¡å‹
    let supported_models = ["mistral", "llama3", "qwen2", "codellama", "gemma", "phi3"];
    
    for model in &supported_models {
        config.model = model.to_string();
        
        let validation_result = config.validate();
        assert!(validation_result.is_ok(), 
               "æ”¯æŒçš„æ¨¡å‹ {} åº”è¯¥éªŒè¯é€šè¿‡: {:?}", model, validation_result);
    }
    
    println!("âœ… æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹éªŒè¯é€šè¿‡");
    
    // æµ‹è¯•ä¸æ”¯æŒçš„æ¨¡å‹
    config.model = "unsupported-model".to_string();
    let validation_result = config.validate();
    assert!(validation_result.is_err(), "ä¸æ”¯æŒçš„æ¨¡å‹åº”è¯¥éªŒè¯å¤±è´¥");
    
    println!("âœ… ä¸æ”¯æŒçš„æ¨¡å‹æ­£ç¡®éªŒè¯å¤±è´¥");
    
    clear_env_vars();
}

#[tokio::test]
async fn test_e2e_ollama_multiple_models() {
    println!("ğŸ§ª E2E æµ‹è¯•ï¼šOllama å¤šæ¨¡å‹åˆ‡æ¢");
    
    if !check_ollama_service().await {
        println!("âš ï¸  Ollama æœåŠ¡æœªè¿è¡Œï¼Œè·³è¿‡é›†æˆæµ‹è¯•");
        return;
    }
    
    let available_models = match get_ollama_models().await {
        Ok(models) => models,
        Err(e) => {
            println!("âš ï¸  æ— æ³•è·å– Ollama æ¨¡å‹: {}, è·³è¿‡å¤šæ¨¡å‹æµ‹è¯•", e);
            return;
        }
    };
    
    println!("å¯ç”¨æ¨¡å‹: {:?}", available_models);
    
    // å¦‚æœæœ‰å¤šä¸ªæ¨¡å‹å¯ç”¨ï¼Œæµ‹è¯•åˆ‡æ¢
    for model in available_models.iter().take(3) { // æœ€å¤šæµ‹è¯•3ä¸ªæ¨¡å‹
        clear_env_vars();
        
        env::set_var("AI_COMMIT_PROVIDER", "ollama");
        env::set_var("AI_COMMIT_MODEL", model);
        
        let mut config = Config::new();
        config.load_from_env();
        
        assert_eq!(config.model, *model);
        
        // å¦‚æœæ˜¯æ”¯æŒçš„æ¨¡å‹ï¼ŒéªŒè¯åº”è¯¥é€šè¿‡
        let ollama_info = ProviderRegistry::get_provider("ollama").unwrap();
        if ollama_info.supported_models.iter().any(|m| model.contains(m)) {
            let validation_result = config.validate();
            assert!(validation_result.is_ok(), 
                   "æ¨¡å‹ {} åº”è¯¥éªŒè¯é€šè¿‡: {:?}", model, validation_result);
        }
        
        println!("âœ… æ¨¡å‹ {} é…ç½®æµ‹è¯•é€šè¿‡", model);
    }
    
    clear_env_vars();
}

#[test]
fn test_e2e_ollama_provider_info_completeness() {
    println!("ğŸ§ª E2E æµ‹è¯•ï¼šOllama æä¾›å•†ä¿¡æ¯å®Œæ•´æ€§");
    
    let ollama = ProviderRegistry::get_provider("ollama")
        .expect("åº”è¯¥èƒ½æ‰¾åˆ° ollama æä¾›å•†");
    
    // éªŒè¯åŸºæœ¬ä¿¡æ¯
    assert_eq!(ollama.name, "ollama");
    assert_eq!(ollama.display_name, "Ollama");
    assert!(!ollama.requires_api_key, "Ollama ä¸éœ€è¦ API Key");
    assert_eq!(ollama.default_url, "http://localhost:11434/api/generate");
    assert_eq!(ollama.api_format, ai_commit::config::providers::ApiFormat::Ollama);
    
    // éªŒè¯æ¨¡å‹é…ç½®
    assert!(!ollama.default_model.is_empty(), "åº”è¯¥æœ‰é»˜è®¤æ¨¡å‹");
    assert!(!ollama.supported_models.is_empty(), "åº”è¯¥æœ‰æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨");
    assert!(ollama.supported_models.contains(&ollama.default_model),
           "é»˜è®¤æ¨¡å‹åº”è¯¥åœ¨æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨ä¸­");
    
    // éªŒè¯ç¯å¢ƒå˜é‡é…ç½®
    assert_eq!(ollama.env_prefix, "AI_COMMIT_OLLAMA");
    assert_eq!(ollama.api_key_env_var(), "AI_COMMIT_OLLAMA_API_KEY");
    assert_eq!(ollama.url_env_var(), "AI_COMMIT_OLLAMA_URL");
    
    // éªŒè¯éªŒè¯é€»è¾‘
    let validation_result = ollama.validate(None);
    assert!(validation_result.is_ok(), "Ollama ä¸éœ€è¦ API Keyï¼ŒéªŒè¯åº”è¯¥é€šè¿‡");
    
    println!("âœ… Ollama æä¾›å•†ä¿¡æ¯å®Œæ•´æ€§éªŒè¯é€šè¿‡");
}

#[tokio::test]
async fn test_e2e_ollama_error_handling() {
    println!("ğŸ§ª E2E æµ‹è¯•ï¼šOllama é”™è¯¯å¤„ç†");
    
    // æµ‹è¯•æ— æ•ˆ URL
    let client = Client::new();
    let result = client
        .post("http://localhost:99999/api/generate") // æ— æ•ˆç«¯å£
        .json(&json!({
            "model": "mistral",
            "prompt": "test",
            "stream": false
        }))
        .timeout(Duration::from_secs(2))
        .send()
        .await;
    
    assert!(result.is_err(), "è¿æ¥æ— æ•ˆ URL åº”è¯¥å¤±è´¥");
    println!("âœ… æ— æ•ˆ URL é”™è¯¯å¤„ç†æ­£ç¡®");
    
    // å¦‚æœ Ollama æœåŠ¡è¿è¡Œï¼Œæµ‹è¯•æ— æ•ˆæ¨¡å‹
    if check_ollama_service().await {
        let result = client
            .post("http://localhost:11434/api/generate")
            .json(&json!({
                "model": "nonexistent-model-12345",
                "prompt": "test",
                "stream": false
            }))
            .timeout(Duration::from_secs(10))
            .send()
            .await;
        
        match result {
            Ok(response) => {
                // æŸäº›æƒ…å†µä¸‹ Ollama å¯èƒ½è¿”å›é”™è¯¯çŠ¶æ€è€Œä¸æ˜¯è¿æ¥é”™è¯¯
                if !response.status().is_success() {
                    println!("âœ… æ— æ•ˆæ¨¡å‹è¿”å›é”™è¯¯çŠ¶æ€: {}", response.status());
                } else {
                    println!("â„¹ï¸  Ollama å¯¹æ— æ•ˆæ¨¡å‹çš„å¤„ç†å¯èƒ½å› ç‰ˆæœ¬è€Œå¼‚");
                }
            }
            Err(_) => {
                println!("âœ… æ— æ•ˆæ¨¡å‹è¯·æ±‚å¤±è´¥ï¼ˆé¢„æœŸè¡Œä¸ºï¼‰");
            }
        }
    }
}

#[test]
fn test_e2e_ollama_config_backwards_compatibility() {
    println!("ğŸ§ª E2E æµ‹è¯•ï¼šOllama é…ç½®å‘åå…¼å®¹æ€§");
    
    clear_env_vars();
    
    // åˆ›å»ºé…ç½®ï¼Œæµ‹è¯•å‘åå…¼å®¹çš„æ–¹æ³•è°ƒç”¨
    let mut config = Config::new();
    config.provider = "ollama".to_string();
    config.load_from_env();
    
    // æµ‹è¯•æ‰€æœ‰å‘åå…¼å®¹çš„æ–¹æ³•
    assert!(!config.ollama_url().is_empty(), "ollama_url() åº”è¯¥è¿”å›æœ‰æ•ˆå€¼");
    assert!(config.deepseek_api_key().is_none(), "deepseek_api_key() åº”è¯¥è¿”å› None");
    assert!(!config.deepseek_url().is_empty(), "deepseek_url() åº”è¯¥è¿”å›æœ‰æ•ˆå€¼");
    
    // æµ‹è¯•é€šç”¨æ–¹æ³•
    assert_eq!(config.current_url(), config.ollama_url());
    assert_eq!(config.current_api_key(), None);
    
    let provider_info = config.current_provider_info();
    assert!(provider_info.is_some());
    assert_eq!(provider_info.unwrap().name, "ollama");
    
    println!("âœ… Ollama å‘åå…¼å®¹æ€§éªŒè¯é€šè¿‡");
    
    clear_env_vars();
}